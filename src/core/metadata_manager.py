"""
í†µí•© ë©”íƒ€ë°ì´í„° ê´€ë¦¬ì

ìƒˆë¡œìš´ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ë©”íƒ€ë°ì´í„° ì œê³µìë¡œë¶€í„°
ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ê´€ë¦¬í•˜ëŠ” í†µí•© ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import asyncio
import logging
import time
from typing import List, Optional, Dict, Any
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

from src.plugin.loader import PluginLoader
from src.plugin.base import SearchResult, ProviderConfig
from src.config.plugin_config import PluginConfigManager
from src.cache.cache_db import CacheDB


logger = logging.getLogger(__name__)


class MetadataManager:
    """í†µí•© ë©”íƒ€ë°ì´í„° ê´€ë¦¬ì"""
    
    # ì„±ëŠ¥ ìµœì í™” ìƒìˆ˜
    SEARCH_TIMEOUT = 10.0  # ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    CACHE_TIMEOUT = 5.0    # ìºì‹œ ì‘ì—… íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    MAX_CONCURRENT_SEARCHES = 3  # ìµœëŒ€ ë™ì‹œ ê²€ìƒ‰ ìˆ˜
    
    def __init__(self, plugin_dir: Path = Path("src/plugin")):
        """
        MetadataManager ì´ˆê¸°í™”
        
        Args:
            plugin_dir: í”ŒëŸ¬ê·¸ì¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.plugin_dir = plugin_dir
        self.plugin_loader = PluginLoader()
        self.config_manager = PluginConfigManager()
        self.cache_db = CacheDB()
        self._executor = ThreadPoolExecutor(max_workers=2)  # ì›Œì»¤ ìˆ˜ ì œí•œ
        self._initialized = False
        self._search_semaphore = asyncio.Semaphore(3)  # ë™ì‹œ ê²€ìƒ‰ ì œí•œ
        
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)  # ë””ë²„ê·¸ ë ˆë²¨ ì„¤ì •
    
    async def initialize(self) -> None:
        """ë©”íƒ€ë°ì´í„° ê´€ë¦¬ì ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸš€ [METADATA] Starting Metadata Manager initialization...")
            start_time = time.time()
            
            # ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (íƒ€ì„ì•„ì›ƒ ì ìš©)
            self.logger.debug("ğŸ’¾ [METADATA] Initializing cache database...")
            try:
                await asyncio.wait_for(
                    self.cache_db.initialize(),
                    timeout=self.CACHE_TIMEOUT
                )
                self.logger.debug("âœ… [METADATA] Cache database initialized successfully")
            except asyncio.TimeoutError:
                self.logger.warning("âš ï¸ [METADATA] Cache initialization timeout, continuing without cache")
            except Exception as e:
                self.logger.warning(f"âš ï¸ [METADATA] Cache initialization failed: {e}, continuing without cache")
            
            # í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ
            self.logger.debug("ğŸ“¦ [METADATA] Loading plugins...")
            load_start = time.time()
            load_results = await self.plugin_loader.load_all_plugins(self.plugin_dir)
            load_elapsed = time.time() - load_start
            self.logger.info(f"ğŸ“¦ [METADATA] Plugin load results: {load_results} (took {load_elapsed:.3f}s)")
            
            # í™œì„±í™”ëœ í”ŒëŸ¬ê·¸ì¸ë“¤ ì´ˆê¸°í™”
            self.logger.debug("ğŸ”§ [METADATA] Initializing active plugins...")
            init_start = time.time()
            
            for plugin_name in self.plugin_loader.get_available_plugins():
                if plugin_name in load_results and load_results[plugin_name]:
                    self.logger.debug(f"ğŸ”§ [METADATA] Initializing plugin: {plugin_name}")
                    
                    # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                    settings = self.config_manager.get_plugin_settings(plugin_name)
                    
                    if settings.enabled:
                        self.logger.debug(f"âœ… [METADATA] Plugin {plugin_name} is enabled, proceeding with initialization")
                        
                        # API í‚¤ ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œë¡œëŠ” ë³´ì•ˆ ì €ì¥ì†Œì—ì„œ)
                        api_key = settings.custom_settings.get('api_key')
                        
                        # ProviderConfig ìƒì„±
                        provider_config = self.config_manager.get_provider_config(
                            plugin_name, api_key
                        )
                        
                        # í”ŒëŸ¬ê·¸ì¸ ì´ˆê¸°í™” (íƒ€ì„ì•„ì›ƒ ì ìš©)
                        try:
                            plugin_start = time.time()
                            success = await asyncio.wait_for(
                                self.plugin_loader.initialize_provider(plugin_name, provider_config),
                                timeout=5.0
                            )
                            plugin_elapsed = time.time() - plugin_start
                            
                            if success:
                                self.logger.info(f"âœ… [METADATA] Successfully initialized plugin: {plugin_name} (took {plugin_elapsed:.3f}s)")
                            else:
                                self.logger.warning(f"âš ï¸ [METADATA] Failed to initialize plugin: {plugin_name} (took {plugin_elapsed:.3f}s)")
                        except asyncio.TimeoutError:
                            self.logger.warning(f"âš ï¸ [METADATA] Plugin initialization timeout: {plugin_name}")
                        except Exception as e:
                            self.logger.error(f"âŒ [METADATA] Plugin initialization error: {plugin_name} - {e}")
                    else:
                        self.logger.debug(f"âŒ [METADATA] Plugin {plugin_name} is disabled, skipping initialization")
                else:
                    self.logger.warning(f"âš ï¸ [METADATA] Plugin {plugin_name} failed to load, skipping initialization")
            
            init_elapsed = time.time() - init_start
            self.logger.debug(f"ğŸ”§ [METADATA] Plugin initialization completed in {init_elapsed:.3f}s")
            
            self._initialized = True
            total_elapsed = time.time() - start_time
            self.logger.info(f"ğŸ‰ [METADATA] Metadata Manager initialization completed in {total_elapsed:.3f}s")
            
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Failed to initialize Metadata Manager: {e}")
            raise
    
    async def close(self) -> None:
        """ë©”íƒ€ë°ì´í„° ê´€ë¦¬ì ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ [METADATA] Starting Metadata Manager cleanup...")
            start_time = time.time()
            
            # í”ŒëŸ¬ê·¸ì¸ë“¤ ì •ë¦¬
            self.logger.debug("ğŸ”§ [METADATA] Closing plugins...")
            await self.plugin_loader.close_all_providers()
            
            # ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬
            self.logger.debug("ğŸ’¾ [METADATA] Closing cache database...")
            try:
                await asyncio.wait_for(
                    self.cache_db.close(),
                    timeout=self.CACHE_TIMEOUT
                )
                self.logger.debug("âœ… [METADATA] Cache database closed successfully")
            except asyncio.TimeoutError:
                self.logger.warning("âš ï¸ [METADATA] Cache close timeout")
            except Exception as e:
                self.logger.warning(f"âš ï¸ [METADATA] Cache close error: {e}")
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            self.logger.debug("ğŸ§µ [METADATA] Shutting down thread pool...")
            self._executor.shutdown(wait=False)  # ë¹„ë™ê¸° ì •ë¦¬
            
            self._initialized = False
            elapsed = time.time() - start_time
            self.logger.info(f"âœ… [METADATA] Metadata Manager cleanup completed in {elapsed:.3f}s")
            
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Error during Metadata Manager cleanup: {e}")
    
    async def search(self, title: str, year: Optional[int] = None, season: Optional[int] = None, is_special: bool = False) -> Optional[SearchResult]:
        """
        ëª¨ë“  í™œì„±í™”ëœ í”ŒëŸ¬ê·¸ì¸ì—ì„œ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ (íƒ€ì„ì•„ì›ƒ ë° ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
        
        Args:
            title: ê²€ìƒ‰í•  ì œëª©
            year: ì—°ë„ (ì˜µì…˜)
            season: ì‹œì¦Œ ë²ˆí˜¸ (ì˜µì…˜)
            is_special: íŠ¹ì§‘ ì—¬ë¶€ (ì˜µì…˜)
            
        Returns:
            SearchResult or None: ê²€ìƒ‰ ê²°ê³¼ ë˜ëŠ” None
        """
        if not self._initialized:
            raise RuntimeError("Metadata Manager is not initialized")
        
        search_start = time.time()
        self.logger.info(f"ğŸ” [METADATA] Starting search for: '{title}' (year: {year})")
        
        async with self._search_semaphore:  # ë™ì‹œ ê²€ìƒ‰ ì œí•œ
            self.logger.debug(f"ğŸ”’ [METADATA] Acquired search semaphore for: '{title}'")
            
            try:
                # ìºì‹œ í™•ì¸ (íƒ€ì„ì•„ì›ƒ ì ìš©)
                cache_key = self._generate_cache_key(title, year)
                self.logger.debug(f"ğŸ’¾ [METADATA] Checking cache with key: {cache_key}")
                
                cached_result = None
                cache_start = time.time()
                
                try:
                    cached_result = await asyncio.wait_for(
                        self.cache_db.get_cache(cache_key),
                        timeout=self.CACHE_TIMEOUT
                    )
                    cache_elapsed = time.time() - cache_start
                    self.logger.debug(f"ğŸ’¾ [METADATA] Cache lookup completed in {cache_elapsed:.3f}s")
                except asyncio.TimeoutError:
                    self.logger.warning(f"âš ï¸ [METADATA] Cache lookup timeout for: {title}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ [METADATA] Cache lookup failed for {title}: {e}")
                
                if cached_result:
                    self.logger.info(f"âœ… [METADATA] Cache hit for: {title}")
                    return SearchResult(**cached_result)
                
                # ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ì—ì„œ ê²€ìƒ‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)
                self.logger.debug(f"ğŸ” [METADATA] No cache hit, searching all providers for: '{title}'")
                search_providers_start = time.time()
                
                try:
                    results = await asyncio.wait_for(
                        self.plugin_loader.search_all_providers(title, year, season, is_special),
                        timeout=self.SEARCH_TIMEOUT
                    )
                    search_providers_elapsed = time.time() - search_providers_start
                    self.logger.debug(f"ğŸ” [METADATA] Provider search completed in {search_providers_elapsed:.3f}s")
                    self.logger.debug(f"ğŸ“Š [METADATA] Found {len(results)} results from providers")
                except asyncio.TimeoutError:
                    self.logger.warning(f"âš ï¸ [METADATA] Search timeout for: {title}")
                    return None
                except Exception as e:
                    self.logger.error(f"âŒ [METADATA] Search failed for {title}: {e}")
                    return None
                
                if not results:
                    self.logger.warning(f"âš ï¸ [METADATA] No results found for: {title}")
                    return None
                
                # ê°€ì¥ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²°ê³¼ ì„ íƒ
                self.logger.debug(f"ğŸ¯ [METADATA] Selecting best result from {len(results)} candidates")
                selection_start = time.time()
                best_result = self._select_best_result(results, title, year)
                selection_elapsed = time.time() - selection_start
                self.logger.debug(f"ğŸ¯ [METADATA] Result selection completed in {selection_elapsed:.3f}s")
                
                if best_result:
                    # ìºì‹œì— ì €ì¥ (ë¹„ë™ê¸°, ì—ëŸ¬ ë¬´ì‹œ)
                    self.logger.debug(f"ğŸ’¾ [METADATA] Caching result for: {title}")
                    try:
                        asyncio.create_task(
                            self._cache_result_async(cache_key, best_result, year)
                        )
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ [METADATA] Failed to cache result: {e}")
                
                total_elapsed = time.time() - search_start
                self.logger.info(f"âœ… [METADATA] Search completed for '{title}' in {total_elapsed:.3f}s")
                return best_result
                
            except Exception as e:
                total_elapsed = time.time() - search_start
                self.logger.error(f"âŒ [METADATA] Search error for {title} after {total_elapsed:.3f}s: {e}")
                return None
            finally:
                self.logger.debug(f"ğŸ”“ [METADATA] Released search semaphore for: '{title}'")
    
    async def _cache_result_async(self, cache_key: str, result: SearchResult, year: Optional[int] = None) -> None:
        """ë¹„ë™ê¸° ìºì‹œ ì €ì¥ (ì—ëŸ¬ ë¬´ì‹œ)"""
        try:
            cache_start = time.time()
            await asyncio.wait_for(
                self.cache_db.set_cache(cache_key, result.__dict__, year),
                timeout=self.CACHE_TIMEOUT
            )
            cache_elapsed = time.time() - cache_start
            self.logger.debug(f"ğŸ’¾ [METADATA] Async cache save completed in {cache_elapsed:.3f}s")
        except Exception as e:
            self.logger.debug(f"âš ï¸ [METADATA] Async cache save failed: {e}")
    
    async def search_with_fallback(self, title: str, year: Optional[int] = None) -> Optional[SearchResult]:
        """
        í´ë°± ì „ëµì„ ì‚¬ìš©í•œ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)
        
        Args:
            title: ê²€ìƒ‰í•  ì œëª©
            year: ì—°ë„ (ì˜µì…˜)
            
        Returns:
            SearchResult or None: ê²€ìƒ‰ ê²°ê³¼ ë˜ëŠ” None
        """
        fallback_start = time.time()
        self.logger.info(f"ğŸ”„ [METADATA] Starting fallback search for: '{title}' (year: {year})")
        
        try:
            # 1ì°¨ ê²€ìƒ‰: ì •í™•í•œ ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
            self.logger.debug(f"ğŸ” [METADATA] Fallback step 1: Exact title search for '{title}'")
            result = await self.search(title, year)
            if result:
                self.logger.info(f"âœ… [METADATA] Fallback step 1 successful for '{title}'")
                return result
            
            # 2ì°¨ ê²€ìƒ‰: ì œëª© ì •ì œ í›„ ê²€ìƒ‰
            self.logger.debug(f"ğŸ”§ [METADATA] Fallback step 2: Cleaned title search")
            from src.utils.file_cleaner import FileCleaner
            clean_title = FileCleaner.clean_title(title)
            
            if clean_title != title:
                self.logger.info(f"ğŸ”„ [METADATA] Trying with cleaned title: '{clean_title}' (original: '{title}')")
                result = await self.search(clean_title, year)
                if result:
                    self.logger.info(f"âœ… [METADATA] Fallback step 2 successful with cleaned title")
                    return result
            
            # 3ì°¨ ê²€ìƒ‰: ì—°ë„ ì—†ì´ ê²€ìƒ‰
            if year:
                self.logger.debug(f"ğŸ”„ [METADATA] Fallback step 3: Search without year")
                self.logger.info(f"ğŸ”„ [METADATA] Trying without year: '{title}'")
                result = await self.search(title, None)
                if result:
                    self.logger.info(f"âœ… [METADATA] Fallback step 3 successful without year")
                    return result
            
            total_elapsed = time.time() - fallback_start
            self.logger.warning(f"âš ï¸ [METADATA] All fallback steps failed for '{title}' after {total_elapsed:.3f}s")
            return None
            
        except Exception as e:
            total_elapsed = time.time() - fallback_start
            self.logger.error(f"âŒ [METADATA] Fallback search error for {title} after {total_elapsed:.3f}s: {e}")
            return None
    
    async def batch_search(self, titles: List[str], years: Optional[List[Optional[int]]] = None) -> List[Optional[SearchResult]]:
        """
        ë°°ì¹˜ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ (ì„±ëŠ¥ ìµœì í™”)
        
        Args:
            titles: ê²€ìƒ‰í•  ì œëª© ëª©ë¡
            years: ì—°ë„ ëª©ë¡ (ì˜µì…˜)
            
        Returns:
            List[Optional[SearchResult]]: ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
        """
        if years is None:
            years = [None] * len(titles)
        
        if len(titles) != len(years):
            raise ValueError("Titles and years lists must have the same length")
        
        batch_start = time.time()
        self.logger.info(f"ğŸš€ [METADATA] Starting batch search for {len(titles)} titles")
        
        # ë™ì‹œì„± ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´
        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_SEARCHES)
        
        async def search_with_semaphore(title: str, year: Optional[int]) -> Optional[SearchResult]:
            async with semaphore:
                self.logger.debug(f"ğŸ”’ [METADATA] Acquired batch semaphore for: '{title}'")
                try:
                    result = await self.search_with_fallback(title, year)
                    self.logger.debug(f"ğŸ”“ [METADATA] Released batch semaphore for: '{title}'")
                    return result
                except Exception as e:
                    self.logger.error(f"âŒ [METADATA] Batch search failed for {title}: {e}")
                    self.logger.debug(f"ğŸ”“ [METADATA] Released batch semaphore for: '{title}' (error)")
                    return None
        
        # ëª¨ë“  ê²€ìƒ‰ íƒœìŠ¤í¬ ìƒì„±
        self.logger.debug("ğŸ“‹ [METADATA] Creating batch search tasks...")
        tasks = [search_with_semaphore(title, year) for title, year in zip(titles, years)]
        
        # ê²°ê³¼ ìˆ˜ì§‘ (íƒ€ì„ì•„ì›ƒ ì ìš©)
        self.logger.debug("ğŸš€ [METADATA] Starting parallel batch processing...")
        process_start = time.time()
        
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=len(titles) * 2.0  # íŒŒì¼ë‹¹ 2ì´ˆì”© í—ˆìš©
            )
            
            process_elapsed = time.time() - process_start
            
            # ì˜ˆì™¸ ì²˜ë¦¬
            self.logger.debug("ğŸ” [METADATA] Processing batch results and handling exceptions...")
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    self.logger.error(f"âŒ [METADATA] Batch task {i} failed with exception: {result}")
                    processed_results.append(None)
                else:
                    processed_results.append(result)
            
            total_elapsed = time.time() - batch_start
            successful = sum(1 for r in processed_results if r is not None)
            
            self.logger.info(f"ğŸ‰ [METADATA] Batch search completed!")
            self.logger.info(f"ğŸ“Š [METADATA] Batch Statistics:")
            self.logger.info(f"   - Total titles: {len(titles)}")
            self.logger.info(f"   - Successful: {successful}")
            self.logger.info(f"   - Failed: {len(titles) - successful}")
            self.logger.info(f"   - Processing time: {process_elapsed:.3f}s")
            self.logger.info(f"   - Total time: {total_elapsed:.3f}s")
            self.logger.info(f"   - Average time per title: {process_elapsed/len(titles):.3f}s")
            
            return processed_results
            
        except asyncio.TimeoutError:
            total_elapsed = time.time() - batch_start
            self.logger.warning(f"âš ï¸ [METADATA] Batch search timeout after {total_elapsed:.3f}s")
            return [None] * len(titles)
        except Exception as e:
            total_elapsed = time.time() - batch_start
            self.logger.error(f"âŒ [METADATA] Batch search error after {total_elapsed:.3f}s: {e}")
            return [None] * len(titles)
    
    def _select_best_result(self, results: List[SearchResult], title: str, year: Optional[int] = None) -> Optional[SearchResult]:
        """
        ì—¬ëŸ¬ ê²°ê³¼ ì¤‘ ìµœì ì˜ ê²°ê³¼ ì„ íƒ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
        
        Args:
            results: ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
            title: ì›ë³¸ ê²€ìƒ‰ ì œëª©
            year: ì—°ë„ (ì˜µì…˜)
            
        Returns:
            SearchResult or None: ìµœì ì˜ ê²°ê³¼
        """
        if not results:
            return None
        
        self.logger.debug(f"ğŸ¯ [METADATA] Selecting best result from {len(results)} candidates")
        
        try:
            # ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
            def calculate_score(result: SearchResult) -> float:
                try:
                    score = 0.0
                    
                    # ì œëª© ìœ ì‚¬ë„ (0-100)
                    from rapidfuzz import fuzz
                    title_similarity = fuzz.ratio(title.lower(), result.title.lower())
                    score += title_similarity
                    
                    # ì—°ë„ ë§¤ì¹­ ë³´ë„ˆìŠ¤
                    if year and result.year:
                        if result.year == year:
                            score += 50
                        elif abs(result.year - year) <= 1:
                            score += 25
                    
                    # í‰ì  ë³´ë„ˆìŠ¤ (0-20)
                    if result.rating:
                        score += min(20, result.rating * 2)
                    
                    # í”ŒëŸ¬ê·¸ì¸ ìš°ì„ ìˆœìœ„ ë³´ë„ˆìŠ¤
                    try:
                        plugin_config = self.config_manager.get_plugin_settings(result.provider)
                        score += plugin_config.priority * 10
                    except Exception:
                        pass  # í”ŒëŸ¬ê·¸ì¸ ì„¤ì • ì—ëŸ¬ ë¬´ì‹œ
                    
                    return score
                except Exception:
                    return 0.0  # ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ ì‹œ 0ì 
            
            # ì ìˆ˜ë¡œ ì •ë ¬
            scored_results = [(result, calculate_score(result)) for result in results]
            scored_results.sort(key=lambda x: x[1], reverse=True)
            
            # ìµœê³  ì ìˆ˜ ê²°ê³¼ ë°˜í™˜
            best_result, best_score = scored_results[0]
            
            self.logger.info(f"ğŸ¯ [METADATA] Selected result: {best_result.title} (score: {best_score:.1f}) from {best_result.provider}")
            
            return best_result
            
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Result selection error: {e}")
            # ì—ëŸ¬ ì‹œ ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
            return results[0] if results else None
    
    def _generate_cache_key(self, title: str, year: Optional[int] = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„± (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)"""
        try:
            from slugify import slugify
        from src.utils.safe_slugify import safe_slugify
            normalized_title = safe_slugify(title, separator='_')
            year_part = f"_{year}" if year else "_any"
            return f"{normalized_title}{year_part}"
        except Exception:
            # slugify ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ í‚¤ ìƒì„±
            safe_title = "".join(c for c in title.lower() if c.isalnum() or c.isspace())
            safe_title = safe_title.replace(" ", "_")
            year_part = f"_{year}" if year else "_any"
            return f"{safe_title}{year_part}"
    
    def get_available_providers(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì ëª©ë¡ ë°˜í™˜"""
        providers = self.plugin_loader.get_available_plugins()
        self.logger.debug(f"ğŸ“‹ [METADATA] Available providers: {providers}")
        return providers
    
    def get_active_providers(self) -> List[str]:
        """í™œì„±í™”ëœ ì œê³µì ëª©ë¡ ë°˜í™˜"""
        providers = self.plugin_loader.get_active_plugins()
        self.logger.debug(f"âœ… [METADATA] Active providers: {providers}")
        return providers
    
    def get_provider_info(self, provider_name: str) -> Dict[str, Any]:
        """ì œê³µì ì •ë³´ ë°˜í™˜"""
        info = self.plugin_loader.get_plugin_info(provider_name)
        self.logger.debug(f"ğŸ“‹ [METADATA] Provider info for {provider_name}: {info}")
        return info
    
    def enable_provider(self, provider_name: str) -> None:
        """ì œê³µì í™œì„±í™”"""
        self.logger.info(f"âœ… [METADATA] Enabling provider: {provider_name}")
        self.config_manager.enable_plugin(provider_name)
    
    def disable_provider(self, provider_name: str) -> None:
        """ì œê³µì ë¹„í™œì„±í™”"""
        self.logger.info(f"âŒ [METADATA] Disabling provider: {provider_name}")
        self.config_manager.disable_plugin(provider_name)
    
    def set_provider_priority(self, provider_name: str, priority: int) -> None:
        """ì œê³µì ìš°ì„ ìˆœìœ„ ì„¤ì •"""
        self.logger.info(f"âš¡ [METADATA] Setting provider priority: {provider_name} = {priority}")
        self.config_manager.set_plugin_priority(provider_name, priority)
    
    async def test_provider_connection(self, provider_name: str) -> bool:
        """ì œê³µì ì—°ê²° í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ì ìš©)"""
        self.logger.debug(f"ğŸ” [METADATA] Testing connection for provider: {provider_name}")
        try:
            if provider_name not in self.plugin_loader.instances:
                self.logger.warning(f"âš ï¸ [METADATA] Provider {provider_name} not found in instances")
                return False
            
            provider = self.plugin_loader.instances[provider_name]
            result = await asyncio.wait_for(
                provider.test_connection(),
                timeout=5.0
            )
            self.logger.info(f"{'âœ…' if result else 'âŒ'} [METADATA] Connection test for {provider_name}: {'SUCCESS' if result else 'FAILED'}")
            return result
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Provider connection test failed for {provider_name}: {e}")
            return False
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        self.logger.debug("ğŸ“Š [METADATA] Getting cache statistics...")
        try:
            stats = {
                "cache_enabled": self.cache_db is not None,
                "cache_file": str(self.cache_db.db_path) if self.cache_db else None
            }
            self.logger.debug(f"ğŸ“Š [METADATA] Cache stats: {stats}")
            return stats
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Cache stats error: {e}")
            return {"cache_enabled": False, "error": str(e)}
    
    async def clear_cache(self) -> None:
        """ìºì‹œ ì •ë¦¬ (íƒ€ì„ì•„ì›ƒ ì ìš©)"""
        self.logger.info("ğŸ§¹ [METADATA] Clearing cache...")
        try:
            if self.cache_db:
                await asyncio.wait_for(
                    self.cache_db.cleanup_cache(),
                    timeout=self.CACHE_TIMEOUT
                )
                self.logger.info("âœ… [METADATA] Cache cleared")
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Cache clear error: {e}")
    
    def export_config(self, export_path: Path) -> None:
        """ì„¤ì • ë‚´ë³´ë‚´ê¸°"""
        self.logger.info(f"ğŸ“¤ [METADATA] Exporting config to: {export_path}")
        try:
            self.config_manager.export_config(export_path)
            self.logger.info("âœ… [METADATA] Config exported")
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Config export error: {e}")
    
    def import_config(self, import_path: Path) -> None:
        """ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
        self.logger.info(f"ğŸ“¥ [METADATA] Importing config from: {import_path}")
        try:
            self.config_manager.import_config(import_path)
            self.logger.info("âœ… [METADATA] Config imported")
        except Exception as e:
            self.logger.error(f"âŒ [METADATA] Config import error: {e}") 