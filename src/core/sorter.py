"""
íŒŒì¼ ì •ë ¬ ë° ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ

ìƒˆë¡œìš´ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì •ë ¬í•˜ê³  ë©”íƒ€ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
import time
from pathlib import Path
from typing import List, Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor

from .metadata_manager import MetadataManager
from ..utils.file_cleaner import FileCleaner



logger = logging.getLogger(__name__)


class AnimeSorter:
    """ì• ë‹ˆë©”ì´ì…˜ íŒŒì¼ ì •ë ¬ê¸° (ìƒˆë¡œìš´ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ ê¸°ë°˜)"""
    
    def __init__(self, plugin_dir: Path = Path("src/plugin")):
        """
        AnimeSorter ì´ˆê¸°í™”
        
        Args:
            plugin_dir: í”ŒëŸ¬ê·¸ì¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.metadata_manager = MetadataManager(plugin_dir)
        self.file_cleaner = FileCleaner()
        self._executor = ThreadPoolExecutor(max_workers=4)
        self._initialized = False
        
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)  # ë””ë²„ê·¸ ë ˆë²¨ ì„¤ì •
    
    async def initialize(self) -> None:
        """ì •ë ¬ê¸° ì´ˆê¸°í™”"""
        try:
            self.logger.info("ðŸš€ [SORTER] Starting AnimeSorter initialization...")
            start_time = time.time()
            
            # ë©”íƒ€ë°ì´í„° ê´€ë¦¬ìž ì´ˆê¸°í™”
            self.logger.debug("ðŸ“‹ [SORTER] Initializing metadata manager...")
            await self.metadata_manager.initialize()
            self.logger.debug("âœ… [SORTER] Metadata manager initialized successfully")
            
            self._initialized = True
            elapsed = time.time() - start_time
            self.logger.info(f"ðŸŽ‰ [SORTER] AnimeSorter initialization completed in {elapsed:.2f}s")
            
        except Exception as e:
            self.logger.error(f"âŒ [SORTER] Failed to initialize AnimeSorter: {e}")
            raise
    
    async def close(self) -> None:
        """ì •ë ¬ê¸° ì •ë¦¬"""
        try:
            self.logger.info("ðŸ§¹ [SORTER] Starting AnimeSorter cleanup...")
            start_time = time.time()
            
            await self.metadata_manager.close()
            self._executor.shutdown(wait=True)
            self._initialized = False
            
            elapsed = time.time() - start_time
            self.logger.info(f"âœ… [SORTER] AnimeSorter cleanup completed in {elapsed:.2f}s")
            
        except Exception as e:
            self.logger.error(f"âŒ [SORTER] Error during AnimeSorter cleanup: {e}")
    
    async def process_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """
        ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ (ìƒì„¸í•œ ë””ë²„ê·¸ ë¡œê·¸ í¬í•¨)
        
        Args:
            file_path: ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict or None: ì²˜ë¦¬ ê²°ê³¼ ë˜ëŠ” None
        """
        if not self._initialized:
            raise RuntimeError("AnimeSorter is not initialized")
        
        file_start_time = time.time()
        self.logger.info(f"ðŸ“ [SORTER] Processing file: {file_path}")
        
        try:
            # 1ë‹¨ê³„: íŒŒì¼ëª… ì •ì œ
            self.logger.debug(f"ðŸ”§ [SORTER] Step 1: Cleaning filename for {file_path.name}")
            clean_start = time.time()
            
            clean_result = self.file_cleaner.clean_filename_static(file_path)
            
            clean_elapsed = time.time() - clean_start
            self.logger.debug(f"âœ… [SORTER] Filename cleaning completed in {clean_elapsed:.3f}s")
            self.logger.debug(f"ðŸ“ [SORTER] Cleaned title: '{clean_result.title}' (original: '{file_path.stem}')")
            
            # 2ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ê²€ìƒ‰
            self.logger.debug(f"ðŸ” [SORTER] Step 2: Searching metadata for '{clean_result.title}'")
            search_start = time.time()
            
            metadata = await self.metadata_manager.search_with_fallback(
                clean_result.title, clean_result.year
            )
            
            search_elapsed = time.time() - search_start
            self.logger.debug(f"âœ… [SORTER] Metadata search completed in {search_elapsed:.3f}s")
            
            if metadata:
                self.logger.debug(f"ðŸŽ¯ [SORTER] Found metadata: {metadata.title} from {metadata.provider}")
                result = {
                    'file_path': str(file_path),
                    'clean_title': clean_result.title,
                    'year': clean_result.year,
                    'metadata': metadata.__dict__,
                    'success': True
                }
                self.logger.info(f"âœ… [SORTER] Successfully processed: {file_path.name}")
            else:
                self.logger.debug(f"âš ï¸ [SORTER] No metadata found for '{clean_result.title}'")
                result = {
                    'file_path': str(file_path),
                    'clean_title': clean_result.title,
                    'year': clean_result.year,
                    'metadata': None,
                    'success': False,
                    'error': 'No metadata found'
                }
                self.logger.warning(f"âš ï¸ [SORTER] No metadata found for: {file_path.name}")
            
            file_elapsed = time.time() - file_start_time
            self.logger.debug(f"â±ï¸ [SORTER] Total file processing time: {file_elapsed:.3f}s")
            return result
                
        except Exception as e:
            file_elapsed = time.time() - file_start_time
            self.logger.error(f"âŒ [SORTER] Error processing file {file_path} after {file_elapsed:.3f}s: {e}")
            return {
                'file_path': str(file_path),
                'metadata': None,
                'success': False,
                'error': str(e)
            }
    
    async def process_directory(self, directory: Path, recursive: bool = True) -> List[Dict[str, Any]]:
        """
        ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ (ìƒì„¸í•œ ë””ë²„ê·¸ ë¡œê·¸ í¬í•¨)
        
        Args:
            directory: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            recursive: í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨ ì—¬ë¶€
            
        Returns:
            List[Dict]: ì²˜ë¦¬ ê²°ê³¼ ëª©ë¡
        """
        if not self._initialized:
            raise RuntimeError("AnimeSorter is not initialized")
        
        dir_start_time = time.time()
        self.logger.info(f"ðŸ“‚ [SORTER] Processing directory: {directory}")
        self.logger.debug(f"ðŸ” [SORTER] Recursive mode: {recursive}")
        
        # ì§€ì›í•˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ í™•ìž¥ìž
        VIDEO_EXTENSIONS = {'.mp4', '.mkv', '.avi', '.mov', '.wmv', '.m4v', '.flv'}
        
        # íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        self.logger.debug("ðŸ“‹ [SORTER] Collecting file list...")
        collect_start = time.time()
        
        files = []
        if recursive:
            for ext in VIDEO_EXTENSIONS:
                files.extend(directory.rglob(f"*{ext}"))
        else:
            for ext in VIDEO_EXTENSIONS:
                files.extend(directory.glob(f"*{ext}"))
        
        collect_elapsed = time.time() - collect_start
        self.logger.info(f"ðŸ“Š [SORTER] Found {len(files)} video files in {directory} (collection took {collect_elapsed:.3f}s)")
        
        if not files:
            self.logger.warning("âš ï¸ [SORTER] No video files found in directory")
            return []
        
        # íŒŒì¼ ì²˜ë¦¬
        self.logger.debug("ðŸš€ [SORTER] Starting file processing...")
        process_start = time.time()
        
        results = []
        for i, file_path in enumerate(files, 1):
            self.logger.debug(f"ðŸ“ [SORTER] Processing file {i}/{len(files)}: {file_path.name}")
            
            result = await self.process_file(file_path)
            results.append(result)
            
            # ì§„í–‰ë¥  ë¡œê·¸
            if i % 10 == 0 or i == len(files):
                progress = (i / len(files)) * 100
                elapsed = time.time() - process_start
                avg_time = elapsed / i
                remaining = (len(files) - i) * avg_time
                self.logger.info(f"ðŸ“ˆ [SORTER] Progress: {progress:.1f}% ({i}/{len(files)}) - Avg: {avg_time:.3f}s/file - ETA: {remaining:.1f}s")
        
        process_elapsed = time.time() - process_start
        total_elapsed = time.time() - dir_start_time
        
        # ê²°ê³¼ í†µê³„
        successful = sum(1 for r in results if r and r.get('success', False))
        failed = len(results) - successful
        
        self.logger.info(f"ðŸŽ‰ [SORTER] Directory processing completed!")
        self.logger.info(f"ðŸ“Š [SORTER] Statistics:")
        self.logger.info(f"   - Total files: {len(files)}")
        self.logger.info(f"   - Successful: {successful}")
        self.logger.info(f"   - Failed: {failed}")
        self.logger.info(f"   - Processing time: {process_elapsed:.3f}s")
        self.logger.info(f"   - Total time: {total_elapsed:.3f}s")
        self.logger.info(f"   - Average time per file: {process_elapsed/len(files):.3f}s")
        
        return results
    
    async def batch_process_files(self, file_paths: List[Path]) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬ (ìƒì„¸í•œ ë””ë²„ê·¸ ë¡œê·¸ í¬í•¨)
        
        Args:
            file_paths: ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ëª©ë¡
            
        Returns:
            List[Dict]: ì²˜ë¦¬ ê²°ê³¼ ëª©ë¡
        """
        if not self._initialized:
            raise RuntimeError("AnimeSorter is not initialized")
        
        batch_start_time = time.time()
        self.logger.info(f"ðŸš€ [SORTER] Starting batch processing of {len(file_paths)} files")
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ë™ì‹œì„± ì œí•œ)
        semaphore = asyncio.Semaphore(4)  # ìµœëŒ€ 4ê°œ ë™ì‹œ ì²˜ë¦¬
        
        async def process_with_semaphore(file_path: Path) -> Dict[str, Any]:
            async with semaphore:
                self.logger.debug(f"ðŸ”’ [SORTER] Acquired semaphore for {file_path.name}")
                try:
                    result = await self.process_file(file_path)
                    self.logger.debug(f"ðŸ”“ [SORTER] Released semaphore for {file_path.name}")
                    return result
                except Exception as e:
                    self.logger.error(f"âŒ [SORTER] Semaphore processing error for {file_path.name}: {e}")
                    self.logger.debug(f"ðŸ”“ [SORTER] Released semaphore for {file_path.name} (error)")
                    return {
                        'file_path': str(file_path),
                        'metadata': None,
                        'success': False,
                        'error': str(e)
                    }
        
        # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
        self.logger.debug("ðŸ“‹ [SORTER] Creating processing tasks...")
        tasks = [process_with_semaphore(file_path) for file_path in file_paths]
        
        self.logger.debug("ðŸš€ [SORTER] Starting parallel processing...")
        process_start = time.time()
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        process_elapsed = time.time() - process_start
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        self.logger.debug("ðŸ” [SORTER] Processing results and handling exceptions...")
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"âŒ [SORTER] Task {i} failed with exception: {result}")
                processed_results.append({
                    'file_path': str(file_paths[i]),
                    'metadata': None,
                    'success': False,
                    'error': str(result)
                })
            else:
                processed_results.append(result)
        
        batch_elapsed = time.time() - batch_start_time
        
        # ê²°ê³¼ í†µê³„
        successful = sum(1 for r in processed_results if r and r.get('success', False))
        failed = len(processed_results) - successful
        
        self.logger.info(f"ðŸŽ‰ [SORTER] Batch processing completed!")
        self.logger.info(f"ðŸ“Š [SORTER] Batch Statistics:")
        self.logger.info(f"   - Total files: {len(file_paths)}")
        self.logger.info(f"   - Successful: {successful}")
        self.logger.info(f"   - Failed: {failed}")
        self.logger.info(f"   - Processing time: {process_elapsed:.3f}s")
        self.logger.info(f"   - Total time: {batch_elapsed:.3f}s")
        self.logger.info(f"   - Average time per file: {process_elapsed/len(file_paths):.3f}s")
        
        return processed_results
    
    def get_available_providers(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° ì œê³µìž ëª©ë¡ ë°˜í™˜"""
        providers = self.metadata_manager.get_available_providers()
        self.logger.debug(f"ðŸ“‹ [SORTER] Available providers: {providers}")
        return providers
    
    def get_active_providers(self) -> List[str]:
        """í™œì„±í™”ëœ ë©”íƒ€ë°ì´í„° ì œê³µìž ëª©ë¡ ë°˜í™˜"""
        providers = self.metadata_manager.get_active_providers()
        self.logger.debug(f"âœ… [SORTER] Active providers: {providers}")
        return providers
    
    def enable_provider(self, provider_name: str) -> None:
        """ì œê³µìž í™œì„±í™”"""
        self.logger.info(f"âœ… [SORTER] Enabling provider: {provider_name}")
        self.metadata_manager.enable_provider(provider_name)
    
    def disable_provider(self, provider_name: str) -> None:
        """ì œê³µìž ë¹„í™œì„±í™”"""
        self.logger.info(f"âŒ [SORTER] Disabling provider: {provider_name}")
        self.metadata_manager.disable_provider(provider_name)
    
    def set_provider_priority(self, provider_name: str, priority: int) -> None:
        """ì œê³µìž ìš°ì„ ìˆœìœ„ ì„¤ì •"""
        self.logger.info(f"âš¡ [SORTER] Setting provider priority: {provider_name} = {priority}")
        self.metadata_manager.set_provider_priority(provider_name, priority)
    
    async def test_provider_connection(self, provider_name: str) -> bool:
        """ì œê³µìž ì—°ê²° í…ŒìŠ¤íŠ¸"""
        self.logger.debug(f"ðŸ” [SORTER] Testing connection for provider: {provider_name}")
        result = await self.metadata_manager.test_provider_connection(provider_name)
        self.logger.info(f"{'âœ…' if result else 'âŒ'} [SORTER] Connection test for {provider_name}: {'SUCCESS' if result else 'FAILED'}")
        return result
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        self.logger.debug("ðŸ“Š [SORTER] Getting cache statistics...")
        stats = await self.metadata_manager.get_cache_stats()
        self.logger.debug(f"ðŸ“Š [SORTER] Cache stats: {stats}")
        return stats
    
    async def clear_cache(self) -> None:
        """ìºì‹œ ì •ë¦¬"""
        self.logger.info("ðŸ§¹ [SORTER] Clearing cache...")
        await self.metadata_manager.clear_cache()
        self.logger.info("âœ… [SORTER] Cache cleared")
    
    def export_config(self, export_path: Path) -> None:
        """ì„¤ì • ë‚´ë³´ë‚´ê¸°"""
        self.logger.info(f"ðŸ“¤ [SORTER] Exporting config to: {export_path}")
        self.metadata_manager.export_config(export_path)
        self.logger.info("âœ… [SORTER] Config exported")
    
    def import_config(self, import_path: Path) -> None:
        """ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
        self.logger.info(f"ðŸ“¥ [SORTER] Importing config from: {import_path}")
        self.metadata_manager.import_config(import_path)
        self.logger.info("âœ… [SORTER] Config imported") 