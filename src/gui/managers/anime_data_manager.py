"""
ì• ë‹ˆë©”ì´ì…˜ ë°ì´í„° ê´€ë¦¬ì
íŒŒì‹±ëœ ì• ë‹ˆë©”ì´ì…˜ íŒŒì¼ë“¤ì˜ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ê³  ê·¸ë£¹í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging

logger = logging.getLogger(__name__)
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any

from PyQt5.QtCore import pyqtSignal

sys.path.append(str(Path(__file__).parent.parent.parent))
from src.core.manager_base import ManagerBase, ManagerConfig, ManagerPriority
from src.core.tmdb_client import TMDBAnimeInfo
from src.core.unified_event_system import EventCategory, EventPriority, get_unified_event_bus


@dataclass
class ParsedItem:
    """íŒŒì‹±ëœ ì• ë‹ˆë©”ì´ì…˜ íŒŒì¼ ì •ë³´"""

    id: str = None
    status: str = "pending"
    sourcePath: str = ""
    detectedTitle: str = ""
    filename: str = ""
    path: str = ""
    title: str = ""
    season: int | None = None
    episode: int | None = None
    year: int | None = None
    tmdbId: int | None = None
    resolution: str | None = None
    group: str | None = None
    codec: str | None = None
    container: str | None = None
    sizeMB: int | None = None
    message: str | None = None
    tmdbMatch: TMDBAnimeInfo | None = None
    parsingConfidence: float | None = None
    groupId: str | None = None
    normalizedTitle: str | None = None

    # anitopyì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ì¶”ê°€ ì •ë³´ë“¤
    video_codec: str | None = None
    audio_codec: str | None = None
    release_group: str | None = None
    file_extension: str | None = None
    episode_title: str | None = None
    source: str | None = None  # TV, Web, Blu-ray ë“±
    quality: str | None = None  # HD, SD ë“±
    language: str | None = None
    subtitles: str | None = None
    crc32: str | None = None

    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        if not self.id:
            import uuid

            self.id = str(uuid.uuid4())[:8]
        if not self.filename and self.sourcePath:
            from pathlib import Path

            self.filename = Path(self.sourcePath).name
        if not self.path and self.sourcePath:
            self.path = self.sourcePath
        if not self.title and self.detectedTitle:
            self.title = self.detectedTitle


class AnimeDataManager(ManagerBase):
    """ì• ë‹ˆë©”ì´ì…˜ ë°ì´í„° ê´€ë¦¬ì"""

    tmdb_search_requested = pyqtSignal(str)
    tmdb_anime_selected = pyqtSignal(str, object)

    def __init__(self, tmdb_client=None, parent=None):
        config = ManagerConfig(
            name="AnimeDataManager",
            priority=ManagerPriority.NORMAL,
            auto_start=True,
            log_level="INFO",
        )
        super().__init__(config, parent)
        self.items: list[ParsedItem] = []
        self.tmdb_client = tmdb_client
        self.group_tmdb_matches = {}
        self.unified_event_bus = get_unified_event_bus()
        self.logger.info(
            f"AnimeDataManager ì´ˆê¸°í™” ì™„ë£Œ (TMDB í´ë¼ì´ì–¸íŠ¸: {'ìˆìŒ' if tmdb_client else 'ì—†ìŒ'})"
        )

    def set_tmdb_client(self, tmdb_client):
        """TMDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        self.tmdb_client = tmdb_client
        self.logger.info(f"TMDB í´ë¼ì´ì–¸íŠ¸ ì—…ë°ì´íŠ¸: {'ìˆìŒ' if tmdb_client else 'ì—†ìŒ'}")

    def add_item(self, item: ParsedItem):
        """ì•„ì´í…œ ì¶”ê°€"""
        self.items.append(item)
        if self.unified_event_bus:
            from src.core.unified_event_system import BaseEvent

            event = BaseEvent(
                source="AnimeDataManager",
                category=EventCategory.MEDIA,
                priority=EventPriority.NORMAL,
                metadata={"item_id": item.id, "title": item.title},
            )
            self.unified_event_bus.publish(event)

    def add_items(self, items: list[ParsedItem]):
        """ì—¬ëŸ¬ ì•„ì´í…œ ì¶”ê°€"""
        self.items.extend(items)

    def get_items(self) -> list[ParsedItem]:
        """ëª¨ë“  ì•„ì´í…œ ë°˜í™˜"""
        return self.items

    def get_item_by_id(self, item_id: str) -> ParsedItem | None:
        """IDë¡œ ì•„ì´í…œ ì°¾ê¸°"""
        for item in self.items:
            if item.id == item_id:
                return item
        return None

    def update_item_status(self, item_id: str, status: str):
        """ì•„ì´í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        item = self.get_item_by_id(item_id)
        if item:
            item.status = status

    def clear_completed_items(self):
        """ì™„ë£Œëœ ì•„ì´í…œë“¤ ì œê±°"""
        self.items = [item for item in self.items if item.status != "parsed"]

    def get_stats(self) -> dict:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        total = len(self.items)
        parsed = len([item for item in self.items if item.status == "parsed"])
        pending = len([item for item in self.items if item.status == "pending"])
        needs_review = len([item for item in self.items if item.status == "needs_review"])
        error = len([item for item in self.items if item.status == "error"])
        skipped = len([item for item in self.items if item.status == "skipped"])
        groups = self.get_grouped_items()
        group_count = len(groups)
        return {
            "total": total,
            "parsed": parsed,
            "pending": pending,
            "needs_review": needs_review,
            "error": error,
            "skipped": skipped,
            "groups": group_count,
        }

    def normalize_title_for_grouping(self, title: str) -> str:
        """ì œëª©ì„ ê·¸ë£¹í™”ìš©ìœ¼ë¡œ ì •ê·œí™” (ê°œì„ ëœ ë²„ì „)"""
        if not title:
            return ""

        # ê¸°ë³¸ ì •ë¦¬
        normalized = title.strip()

        # ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±° (ê´„í˜¸, ëŒ€ê´„í˜¸, íŠ¹ìˆ˜ë¬¸ì)
        suffixes_to_remove = [
            r"\s*\([^)]*\)\s*$",  # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°
            r"\s*\[[^\]]*\]\s*$",  # ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°
            r"\s*-\s*$",  # ëì˜ ëŒ€ì‹œ ì œê±°
            r"\s*\.\s*$",  # ëì˜ ì  ì œê±°
            r"\s*:\s*$",  # ëì˜ ì½œë¡  ì œê±°
        ]

        for pattern in suffixes_to_remove:
            normalized = re.sub(pattern, "", normalized)

        # ì†Œë¬¸ì ë³€í™˜
        normalized = normalized.lower()

        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€)
        normalized = re.sub(r"[^\w\sê°€-í£]", "", normalized)

        # ê³µë°± ì •ê·œí™”
        normalized = re.sub(r"\s+", " ", normalized)

        # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
        patterns_to_remove = [
            r"\bthe\b",
            r"\banimation\b",
            r"\banime\b",
            r"\btv\b",
            r"\bseries\b",
            r"\bseason\b",
            r"\bepisode\b",
            r"\bep\b",
            r"\bova\b",
            r"\bmovie\b",
            r"\bfilm\b",
            r"\bspecial\b",
        ]

        for pattern in patterns_to_remove:
            normalized = re.sub(pattern, "", normalized)

        # ìµœì¢… ê³µë°± ì •ë¦¬
        normalized = re.sub(r"\s+", " ", normalized)

        return normalized.strip()

    def group_similar_titles(self) -> list[ParsedItem]:
        """ìœ ì‚¬í•œ ì œëª©ì„ ê°€ì§„ íŒŒì¼ë“¤ì„ ê·¸ë£¹í™”"""
        if not self.items:
            return self.items
        title_groups = {}
        group_counter = 1
        for item in self.items:
            if not item.title:
                continue
            normalized_title = self.normalize_title_for_grouping(item.title)
            item.normalizedTitle = normalized_title
            best_match = None
            best_similarity = 0.6  # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ ìœ ì‚¬ ì œëª© ê·¸ë£¹í™”
            for existing_title, _group_id in title_groups.items():
                similarity = self.calculate_title_similarity(normalized_title, existing_title)
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = existing_title
            if best_match:
                item.groupId = title_groups[best_match]
                logger.info(
                    "ğŸ”— ê·¸ë£¹í™”: '%s' â†’ ê·¸ë£¹ %s (ìœ ì‚¬ë„: %s)",
                    item.title,
                    item.groupId,
                    best_similarity,
                )
            else:
                new_group_id = f"group_{group_counter:03d}"
                item.groupId = new_group_id
                title_groups[normalized_title] = new_group_id
                group_counter += 1
                logger.info("ğŸ†• ìƒˆ ê·¸ë£¹ ìƒì„±: '%s' â†’ ê·¸ë£¹ %s", item.title, new_group_id)
        logger.info("âœ… ê·¸ë£¹í™” ì™„ë£Œ: %sê°œ íŒŒì¼ â†’ %sê°œ ê·¸ë£¹", len(self.items), len(title_groups))
        return self.items

    def calculate_title_similarity(self, title1: str, title2: str) -> float:
        """ë‘ ì œëª© ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0) - ê°œì„ ëœ ë²„ì „"""
        if not title1 or not title2:
            return 0.0

        # ì •í™•íˆ ê°™ì€ ê²½ìš°
        if title1 == title2:
            return 1.0

        # í•œìª½ì´ ë‹¤ë¥¸ ìª½ì— í¬í•¨ë˜ëŠ” ê²½ìš°
        if title1 in title2 or title2 in title1:
            return 0.9

        # ë‹¨ì–´ ê¸°ë°˜ ìœ ì‚¬ë„ (Jaccard)
        words1 = set(title1.lower().split())
        words2 = set(title2.lower().split())
        if not words1 or not words2:
            return 0.0

        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        jaccard_similarity = intersection / union if union > 0 else 0.0

        # ë¬¸ìì—´ ìœ ì‚¬ë„ (Levenshtein ê¸°ë°˜)
        def levenshtein_ratio(s1: str, s2: str) -> float:
            if len(s1) < len(s2):
                return levenshtein_ratio(s2, s1)
            if len(s2) == 0:
                return 0.0

            previous_row = list(range(len(s2) + 1))
            for i, c1 in enumerate(s1):
                current_row = [i + 1]
                for j, c2 in enumerate(s2):
                    insertions = previous_row[j + 1] + 1
                    deletions = current_row[j] + 1
                    substitutions = previous_row[j] + (c1 != c2)
                    current_row.append(min(insertions, deletions, substitutions))
                previous_row = current_row

            max_len = max(len(s1), len(s2))
            return 1.0 - (previous_row[-1] / max_len) if max_len > 0 else 0.0

        string_similarity = levenshtein_ratio(title1.lower(), title2.lower())

        # ê¸¸ì´ ìœ ì‚¬ë„
        length_diff = abs(len(title1) - len(title2))
        max_length = max(len(title1), len(title2))
        length_similarity = 1.0 - (length_diff / max_length) if max_length > 0 else 0.0

        # ê°€ì¤‘ í‰ê·  (ë‹¨ì–´ ìœ ì‚¬ë„ 40%, ë¬¸ìì—´ ìœ ì‚¬ë„ 40%, ê¸¸ì´ ìœ ì‚¬ë„ 20%)
        return jaccard_similarity * 0.4 + string_similarity * 0.4 + length_similarity * 0.2

    def get_grouped_items(self) -> dict:
        """ê·¸ë£¹ë³„ë¡œ ì •ë¦¬ëœ ì•„ì´í…œë“¤ ë°˜í™˜"""
        groups = {}
        for item in self.items:
            group_id = item.groupId or "ungrouped"
            if group_id not in groups:
                groups[group_id] = []
            groups[group_id].append(item)
        if "ungrouped" in groups and not groups["ungrouped"]:
            del groups["ungrouped"]
        return groups

    def _initialize_impl(self) -> bool:
        """êµ¬í˜„ì²´ë³„ ì´ˆê¸°í™” ë¡œì§"""
        try:
            self.logger.info("AnimeDataManager ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _start_impl(self) -> bool:
        """êµ¬í˜„ì²´ë³„ ì‹œì‘ ë¡œì§"""
        try:
            self.logger.info("AnimeDataManager ì‹œì‘")
            return True
        except Exception as e:
            self.logger.error(f"ì‹œì‘ ì‹¤íŒ¨: {e}")
            return False

    def _stop_impl(self) -> bool:
        """êµ¬í˜„ì²´ë³„ ì¤‘ì§€ ë¡œì§"""
        try:
            self.logger.info("AnimeDataManager ì¤‘ì§€")
            return True
        except Exception as e:
            self.logger.error(f"ì¤‘ì§€ ì‹¤íŒ¨: {e}")
            return False

    def _pause_impl(self) -> bool:
        """êµ¬í˜„ì²´ë³„ ì¼ì‹œì •ì§€ ë¡œì§"""
        try:
            self.logger.info("AnimeDataManager ì¼ì‹œì •ì§€")
            return True
        except Exception as e:
            self.logger.error(f"ì¼ì‹œì •ì§€ ì‹¤íŒ¨: {e}")
            return False

    def _resume_impl(self) -> bool:
        """êµ¬í˜„ì²´ë³„ ì¬ê°œ ë¡œì§"""
        try:
            self.logger.info("AnimeDataManager ì¬ê°œ")
            return True
        except Exception as e:
            self.logger.error(f"ì¬ê°œ ì‹¤íŒ¨: {e}")
            return False

    def _get_custom_health_status(self) -> dict[str, Any] | None:
        """êµ¬í˜„ì²´ë³„ ê±´ê°• ìƒíƒœ ë°˜í™˜"""
        return {
            "item_count": len(self.items),
            "group_count": len(self.get_grouped_items()),
            "tmdb_matches": len(self.group_tmdb_matches),
            "tmdb_client_available": self.tmdb_client is not None,
        }

    def search_tmdb_for_group(self, group_id: str, group_title: str):
        """ê·¸ë£¹ì— ëŒ€í•œ TMDB ê²€ìƒ‰ ì‹¤í–‰"""
        if not self.tmdb_client:
            logger.info("âŒ TMDB í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
        logger.info("ğŸ” TMDB ê²€ìƒ‰ ì‹œì‘: '%s' (ê·¸ë£¹ %s)", group_title, group_id)
        logger.info("ğŸ” ì‹œê·¸ë„ ë°œí–‰: tmdb_search_requested.emit(%s)", group_id)
        self.tmdb_search_requested.emit(group_id)
        logger.info("ğŸ” ì‹œê·¸ë„ ë°œí–‰ ì™„ë£Œ: %s", group_id)

    def set_tmdb_match_for_group(self, group_id: str, tmdb_anime: TMDBAnimeInfo):
        """ê·¸ë£¹ì— TMDB ë§¤ì¹˜ ê²°ê³¼ ì„¤ì •"""
        self.group_tmdb_matches[group_id] = tmdb_anime
        for item in self.items:
            if item.groupId == group_id:
                item.tmdbMatch = tmdb_anime
                item.tmdbId = tmdb_anime.id
                item.status = "tmdb_matched"
        logger.info("âœ… TMDB ë§¤ì¹˜ ì™„ë£Œ: ê·¸ë£¹ %s â†’ %s", group_id, tmdb_anime.name)

    def get_tmdb_match_for_group(self, group_id: str) -> TMDBAnimeInfo | None:
        """ê·¸ë£¹ì˜ TMDB ë§¤ì¹˜ ê²°ê³¼ ë°˜í™˜"""
        return self.group_tmdb_matches.get(group_id)

    def clear_tmdb_matches(self):
        """ëª¨ë“  TMDB ë§¤ì¹˜ ì •ë³´ ì´ˆê¸°í™”"""
        self.group_tmdb_matches.clear()
        for item in self.items:
            item.tmdbMatch = None
            item.tmdbId = None
            if item.status == "tmdb_matched":
                item.status = "pending"
        logger.info("ğŸ”„ ëª¨ë“  TMDB ë§¤ì¹˜ ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

    def get_group_destination_path(self, group_id: str, base_destination: str) -> str:
        """ê·¸ë£¹ì˜ ìµœì¢… ì´ë™ ê²½ë¡œ ìƒì„±"""
        tmdb_anime = self.get_tmdb_match_for_group(group_id)
        if not tmdb_anime:
            return str(Path(base_destination) / "Unknown")
        safe_title = re.sub('[<>:"/\\\\|?*]', "", tmdb_anime.name)
        group_items = [item for item in self.items if item.groupId == group_id]
        if group_items and group_items[0].season:
            season_folder = f"Season{group_items[0].season:02d}"
            return str(Path(base_destination) / safe_title / season_folder)
        return str(Path(base_destination) / safe_title)

    def get_group_display_info(self, group_id: str) -> dict:
        """ê·¸ë£¹ì˜ í‘œì‹œ ì •ë³´ ë°˜í™˜"""
        group_items = [item for item in self.items if item.groupId == group_id]
        if not group_items:
            return {}
        tmdb_anime = self.get_tmdb_match_for_group(group_id)
        episodes = [item.episode for item in group_items if item.episode is not None]
        if episodes:
            min_ep = min(episodes)
            max_ep = max(episodes)
            episode_info = f"E{min_ep:02d}" if min_ep == max_ep else f"E{min_ep:02d}-E{max_ep:02d}"
        else:
            episode_info = "Unknown"
        resolutions = {}
        for item in group_items:
            from src.core.resolution_normalizer import normalize_resolution

            res = normalize_resolution(item.resolution or "Unknown")
            resolutions[res] = resolutions.get(res, 0) + 1
        return {
            "title": tmdb_anime.name if tmdb_anime else group_items[0].title,
            "original_title": tmdb_anime.original_name if tmdb_anime else None,
            "episode_info": episode_info,
            "file_count": len(group_items),
            "resolutions": resolutions,
            "tmdb_id": tmdb_anime.id if tmdb_anime else None,
            "poster_path": tmdb_anime.poster_path if tmdb_anime else None,
            "status": "tmdb_matched" if tmdb_anime else "pending",
        }

    def display_grouped_results(self):
        """ê·¸ë£¹í™”ëœ ê²°ê³¼ë¥¼ ì¶œë ¥"""
        if not self.items:
            return None
        groups = self.get_grouped_items()
        logger.info("\nğŸ“Š ìŠ¤ìº” ê²°ê³¼: %sê°œ íŒŒì¼ â†’ %sê°œ ê·¸ë£¹", len(self.items), len(groups))
        for group_id, items in groups.items():
            if group_id == "ungrouped":
                continue
            title = items[0].title if items else "Unknown"
            episodes = [item.episode for item in items if item.episode is not None]
            if episodes:
                min_ep = min(episodes)
                max_ep = max(episodes)
                if min_ep == max_ep:
                    episode_info = f"E{min_ep:02d}"
                else:
                    episode_info = f"E{min_ep:02d}-E{max_ep:02d}"
            else:
                episode_info = "Unknown"
            resolutions = {}
            for item in items:
                from src.core.resolution_normalizer import normalize_resolution

                res = normalize_resolution(item.resolution or "Unknown")
                resolutions[res] = resolutions.get(res, 0) + 1
            resolution_info = ", ".join([f"{res}: {count}" for res, count in resolutions.items()])
            logger.info(
                "ğŸ”— %s (%s) - %sê°œ íŒŒì¼ [%s]", title, episode_info, len(items), resolution_info
            )
        return groups
