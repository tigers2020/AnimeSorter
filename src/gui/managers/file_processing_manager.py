"""
íŒŒì¼ ì²˜ë¦¬ ê´€ë¦¬ì
íŒŒì¼ ìŠ¤ìº”, íŒŒì‹±, ì •ë¦¬ ê³„íš ìˆ˜ë¦½ ë“±ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import shutil
import sys
import threading
import time
from collections.abc import Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent.parent))
from core.file_manager import FileManager
from core.file_parser import FileParser

from .anime_data_manager import ParsedItem


@dataclass
class FileProcessingPlan:
    """íŒŒì¼ ì²˜ë¦¬ ê³„íš"""

    source_path: str
    target_path: str
    action: str  # 'move', 'copy', 'rename'
    backup_path: str | None = None
    estimated_size: int | None = None
    conflicts: list[str] = None

    def __post_init__(self):
        if self.conflicts is None:
            self.conflicts = []


@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„"""

    total_files: int = 0
    processed_files: int = 0
    skipped_files: int = 0
    error_files: int = 0
    total_size_mb: int = 0
    estimated_time_seconds: int = 0


class FileProcessingManager:
    """íŒŒì¼ ì²˜ë¦¬ ê´€ë¦¬ì"""

    def __init__(self, destination_root: str = "", safe_mode: bool = True):
        """ì´ˆê¸°í™”"""
        self.destination_root = destination_root
        self.safe_mode = safe_mode
        self.file_parser = FileParser()
        self.file_manager = FileManager(destination_root=destination_root, safe_mode=safe_mode)

        # ì²˜ë¦¬ ê³„íš ì €ì¥
        self.processing_plans: list[FileProcessingPlan] = []
        self.processing_stats = ProcessingStats()

        print("âœ… FileProcessingManager ì´ˆê¸°í™” ì™„ë£Œ")

    def scan_directory(self, directory_path: str, recursive: bool = True) -> list[str]:
        """ë””ë ‰í† ë¦¬ ìŠ¤ìº”í•˜ì—¬ ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°"""
        if not Path(directory_path).exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory_path}")
            return []

        video_extensions = {".mkv", ".mp4", ".avi", ".mov", ".wmv", ".flv", ".webm", ".m4v"}
        video_files = []

        try:
            if recursive:
                for root, _dirs, _files in Path(directory_path).rglob("*"):
                    if root.is_file() and root.suffix.lower() in video_extensions:
                        video_files.append(str(root))
            else:
                for file_path in Path(directory_path).iterdir():
                    if file_path.is_file() and file_path.suffix.lower() in video_extensions:
                        video_files.append(str(file_path))

            print(f"ğŸ” ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì™„ë£Œ: {len(video_files)}ê°œ ë¹„ë””ì˜¤ íŒŒì¼ ë°œê²¬")
            return video_files

        except Exception as e:
            print(f"âŒ ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì˜¤ë¥˜: {e}")
            return []

    def parse_files(self, file_paths: list[str]) -> list[ParsedItem]:
        """íŒŒì¼ë“¤ì„ íŒŒì‹±í•˜ì—¬ ParsedItem ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        if not file_paths:
            return []

        print(f"ğŸ” íŒŒì¼ íŒŒì‹± ì‹œì‘: {len(file_paths)}ê°œ íŒŒì¼")

        parsed_items = []
        for i, file_path in enumerate(file_paths):
            try:
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = int((i / len(file_paths)) * 100)
                print(f"ì§„í–‰ë¥ : {progress}% - {Path(file_path).name}")

                # íŒŒì¼ íŒŒì‹±
                parsed_metadata = self.file_parser.parse_filename(file_path)

                if parsed_metadata and parsed_metadata.title:
                    # íŒŒì¼ í¬ê¸° ê³„ì‚°
                    file_size = Path(file_path).stat().st_size
                    size_mb = file_size // (1024 * 1024)

                    # ParsedItem ìƒì„±
                    parsed_item = ParsedItem(
                        sourcePath=file_path,
                        detectedTitle=parsed_metadata.title,
                        title=parsed_metadata.title,
                        season=parsed_metadata.season or 1,
                        episode=parsed_metadata.episode or 1,
                        resolution=parsed_metadata.resolution or "Unknown",
                        container=parsed_metadata.container or "Unknown",
                        codec=parsed_metadata.codec or "Unknown",
                        year=parsed_metadata.year,
                        group=parsed_metadata.group or "Unknown",
                        sizeMB=size_mb,
                        status="pending",
                        parsingConfidence=parsed_metadata.confidence or 0.0,
                    )
                    parsed_items.append(parsed_item)

                    print(
                        f"âœ… íŒŒì‹± ì„±ê³µ: {parsed_metadata.title} S{parsed_item.season:02d}E{parsed_item.episode:02d}"
                    )
                else:
                    # íŒŒì‹± ì‹¤íŒ¨
                    parsed_item = ParsedItem(
                        sourcePath=file_path,
                        detectedTitle="Unknown",
                        title="Unknown",
                        status="error",
                        parsingConfidence=0.0,
                    )
                    parsed_items.append(parsed_item)
                    print(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {Path(file_path).name}")

            except Exception as e:
                print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {file_path} - {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ
                parsed_item = ParsedItem(
                    sourcePath=file_path,
                    detectedTitle="Error",
                    title="Error",
                    status="error",
                    parsingConfidence=0.0,
                )
                parsed_items.append(parsed_item)

        print(f"âœ… íŒŒì¼ íŒŒì‹± ì™„ë£Œ: {len(parsed_items)}ê°œ ì•„ì´í…œ ìƒì„±")
        return parsed_items

    def create_processing_plans(
        self, parsed_items: list[ParsedItem], naming_scheme: str = "standard"
    ) -> list[FileProcessingPlan]:
        """íŒŒì¼ ì²˜ë¦¬ ê³„íš ìƒì„±"""
        if not parsed_items:
            return []

        print(f"ğŸ“‹ ì²˜ë¦¬ ê³„íš ìƒì„± ì‹œì‘: {len(parsed_items)}ê°œ ì•„ì´í…œ")

        self.processing_plans = []
        total_size = 0

        for item in parsed_items:
            if item.status == "error":
                continue

            try:
                # ëŒ€ìƒ ê²½ë¡œ ìƒì„±
                target_path = self._generate_target_path(item, naming_scheme)

                # ë°±ì—… ê²½ë¡œ ìƒì„± (ì•ˆì „ ëª¨ë“œì¸ ê²½ìš°)
                backup_path = None
                if self.safe_mode and Path(target_path).exists():
                    backup_path = self._generate_backup_path(target_path)

                # íŒŒì¼ í¬ê¸° ê³„ì‚°
                file_size = (
                    Path(item.sourcePath).stat().st_size if Path(item.sourcePath).exists() else 0
                )
                size_mb = file_size // (1024 * 1024)
                total_size += size_mb

                # ì¶©ëŒ í™•ì¸
                conflicts = self._check_conflicts(target_path)

                # ì²˜ë¦¬ ê³„íš ìƒì„±
                plan = FileProcessingPlan(
                    source_path=item.sourcePath,
                    target_path=target_path,
                    action="copy" if self.safe_mode else "move",
                    backup_path=backup_path,
                    estimated_size=size_mb,
                    conflicts=conflicts,
                )

                self.processing_plans.append(plan)

            except Exception as e:
                print(f"âŒ ê³„íš ìƒì„± ì˜¤ë¥˜: {item.sourcePath} - {e}")

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.processing_stats.total_files = len(self.processing_plans)
        self.processing_stats.total_size_mb = total_size
        self.processing_stats.estimated_time_seconds = self._estimate_processing_time(total_size)

        print(f"âœ… ì²˜ë¦¬ ê³„íš ìƒì„± ì™„ë£Œ: {len(self.processing_plans)}ê°œ ê³„íš")
        return self.processing_plans

    def _generate_target_path(self, item: ParsedItem, naming_scheme: str) -> str:
        """ëŒ€ìƒ ê²½ë¡œ ìƒì„±"""
        if not self.destination_root:
            return item.sourcePath

        # ê¸°ë³¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°
        base_dir = (
            Path(self.destination_root)
            / (item.title or "Unknown")
            / (f"Season {item.season:02d}" if item.season else "Unknown")
        )

        # íŒŒì¼ëª… ìƒì„±
        if naming_scheme == "standard":
            filename = f"{item.title} - S{item.season:02d}E{item.episode:02d}"
        elif naming_scheme == "compact":
            filename = f"S{item.season:02d}E{item.episode:02d}"
        else:
            filename = Path(item.sourcePath).stem

        # í•´ìƒë„ ì •ë³´ ì¶”ê°€
        if item.resolution and item.resolution != "Unknown":
            filename += f" [{item.resolution}]"

        # í™•ì¥ì ì¶”ê°€
        extension = Path(item.sourcePath).suffix
        filename += extension

        # ì „ì²´ ê²½ë¡œ ìƒì„±
        return str(base_dir / filename)

    def _generate_backup_path(self, original_path: str) -> str:
        """ë°±ì—… ê²½ë¡œ ìƒì„±"""
        path = Path(original_path)
        backup_name = f"{path.stem}_backup_{int(time.time())}{path.suffix}"
        backup_path = path.parent / backup_name
        return str(backup_path)

    def _check_conflicts(self, target_path: str) -> list[str]:
        """íŒŒì¼ ì¶©ëŒ í™•ì¸"""
        conflicts = []

        if Path(target_path).exists():
            conflicts.append("íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•¨")

        # ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
        target_dir = Path(target_path).parent
        if not target_dir.exists() or not os.access(str(target_dir), os.W_OK):
            conflicts.append("ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ ì—†ìŒ")

        return conflicts

    def _estimate_processing_time(self, total_size_mb: int) -> int:
        """ì²˜ë¦¬ ì‹œê°„ ì¶”ì • (ì´ˆ ë‹¨ìœ„)"""
        # í‰ê·  ì²˜ë¦¬ ì†ë„: 100MB/ì´ˆ (ë³µì‚¬ ê¸°ì¤€)
        estimated_seconds = total_size_mb // 100

        # ìµœì†Œ 1ì´ˆ
        return max(1, estimated_seconds)

    def simulate_processing(self) -> dict[str, any]:
        """íŒŒì¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
        if not self.processing_plans:
            return {"error": "ì²˜ë¦¬ ê³„íšì´ ì—†ìŠµë‹ˆë‹¤"}

        print("ğŸ­ íŒŒì¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")

        simulation_results = {
            "total_files": len(self.processing_plans),
            "total_size_mb": self.processing_stats.total_size_mb,
            "estimated_time": self.processing_stats.estimated_time_seconds,
            "conflicts": [],
            "success_count": 0,
            "error_count": 0,
        }

        for plan in self.processing_plans:
            if plan.conflicts:
                simulation_results["conflicts"].append(
                    {
                        "source": plan.source_path,
                        "target": plan.target_path,
                        "conflicts": plan.conflicts,
                    }
                )
                simulation_results["error_count"] += 1
            else:
                simulation_results["success_count"] += 1

        print(
            f"âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: {simulation_results['success_count']}ê°œ ì„±ê³µ, {simulation_results['error_count']}ê°œ ì¶©ëŒ"
        )
        return simulation_results

    def execute_processing(
        self,
        dry_run: bool = True,
        progress_callback: Callable[[int], None] | None = None,
        max_workers: int = 4,
    ) -> dict[str, any]:
        """íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬ ë° ì§„í–‰ ì½œë°± ì§€ì›)"""
        if not self.processing_plans:
            return {"error": "ì²˜ë¦¬ ê³„íšì´ ì—†ìŠµë‹ˆë‹¤"}

        if dry_run:
            print("ğŸ­ ë“œë¼ì´ ëŸ° ëª¨ë“œë¡œ íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰")
        else:
            print("ğŸš€ ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰")

        results = {"processed": [], "errors": [], "total_processed": 0, "total_errors": 0}

        total = len(self.processing_plans)
        processed_counter = 0
        lock = threading.Lock()

        def process_one(plan: FileProcessingPlan) -> tuple[bool, FileProcessingPlan, str | None]:
            try:
                if plan.conflicts:
                    return (False, plan, "ì¶©ëŒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
                if dry_run:
                    return (True, plan, None)
                ok = self._execute_single_plan(plan)
                return (ok, plan, None if ok else "íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
            except Exception as e:
                return (False, plan, str(e))

        # ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_plan = {
                executor.submit(process_one, plan): plan for plan in self.processing_plans
            }
            for future in as_completed(future_to_plan):
                success, plan, error = future.result()
                with lock:
                    processed_counter += 1
                    progress = int((processed_counter / total) * 100)
                    if progress_callback:
                        progress_callback(progress)
                if success:
                    results["processed"].append(plan)
                    results["total_processed"] += 1
                else:
                    results["errors"].append(
                        {
                            "source": plan.source_path,
                            "target": plan.target_path,
                            "error": error or "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜",
                        }
                    )
                    results["total_errors"] += 1

        # í†µê³„ ì—…ë°ì´íŠ¸
        if not dry_run:
            self.processing_stats.processed_files = results["total_processed"]
            self.processing_stats.error_files = results["total_errors"]

        print(
            f"âœ… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {results['total_processed']}ê°œ ì„±ê³µ, {results['total_errors']}ê°œ ì˜¤ë¥˜"
        )
        return results

    def _execute_single_plan(self, plan: FileProcessingPlan) -> bool:
        """ë‹¨ì¼ ì²˜ë¦¬ ê³„íš ì‹¤í–‰"""
        try:
            # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±
            target_dir = Path(plan.target_path).parent
            target_dir.mkdir(parents=True, exist_ok=True)

            # ë°±ì—… ìƒì„± (í•„ìš”í•œ ê²½ìš°)
            if plan.backup_path and Path(plan.target_path).exists():
                shutil.copy2(plan.target_path, plan.backup_path)
                print(f"ğŸ’¾ ë°±ì—… ìƒì„±: {plan.backup_path}")

            # íŒŒì¼ ì²˜ë¦¬
            if plan.action == "copy":
                shutil.copy2(plan.source_path, plan.target_path)
            elif plan.action == "move":
                shutil.move(plan.source_path, plan.target_path)

            print(
                f"âœ… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {Path(plan.source_path).name} â†’ {Path(plan.target_path).name}"
            )
            return True

        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {plan.source_path} - {e}")
            return False

    def get_processing_stats(self) -> ProcessingStats:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return self.processing_stats

    def clear_plans(self):
        """ì²˜ë¦¬ ê³„íš ì´ˆê¸°í™”"""
        self.processing_plans.clear()
        self.processing_stats = ProcessingStats()
        print("ğŸ—‘ï¸ ì²˜ë¦¬ ê³„íš ì´ˆê¸°í™” ì™„ë£Œ")

    def export_processing_report(self, filepath: str):
        """ì²˜ë¦¬ ê³„íšì„ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            report = {
                "stats": {
                    "total_files": self.processing_stats.total_files,
                    "total_size_mb": self.processing_stats.total_size_mb,
                    "estimated_time_seconds": self.processing_stats.estimated_time_seconds,
                },
                "plans": [],
            }

            for plan in self.processing_plans:
                plan_dict = {
                    "source_path": plan.source_path,
                    "target_path": plan.target_path,
                    "action": plan.action,
                    "backup_path": plan.backup_path,
                    "estimated_size": plan.estimated_size,
                    "conflicts": plan.conflicts,
                }
                report["plans"].append(plan_dict)

            import json

            with Path(filepath).open("w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            print(f"âœ… ì²˜ë¦¬ ê³„íš ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filepath}")

        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ê³„íš ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")

    def create_processing_plan(
        self, parsed_items: list[ParsedItem], organize_mode: str = "move"
    ) -> list[FileProcessingPlan]:
        """íŒŒì‹±ëœ ì•„ì´í…œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬ ê³„íš ìƒì„±"""
        if not parsed_items:
            return []

        print(f"ğŸ“‹ ì²˜ë¦¬ ê³„íš ìƒì„± ì‹œì‘: {len(parsed_items)}ê°œ ì•„ì´í…œ")

        plans = []
        for item in parsed_items:
            try:
                # ëŒ€ìƒ ê²½ë¡œ ìƒì„±
                target_path = self._generate_target_path(item)

                # ì²˜ë¦¬ ê³„íš ìƒì„±
                plan = FileProcessingPlan(
                    source_path=item.sourcePath or item.path,
                    target_path=target_path,
                    action=organize_mode,
                    estimated_size=(
                        Path(item.sourcePath or item.path).stat().st_size
                        if Path(item.sourcePath or item.path).exists()
                        else None
                    ),
                )

                # ì¶©ëŒ ê²€ì‚¬
                if Path(target_path).exists():
                    plan.conflicts.append(f"ëŒ€ìƒ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•¨: {target_path}")

                plans.append(plan)

            except Exception as e:
                print(f"âš ï¸ ì²˜ë¦¬ ê³„íš ìƒì„± ì‹¤íŒ¨ ({item.sourcePath or item.path}): {e}")

        self.processing_plans = plans
        self.processing_stats.total_files = len(plans)

        print(f"âœ… ì²˜ë¦¬ ê³„íš ìƒì„± ì™„ë£Œ: {len(plans)}ê°œ ê³„íš")
        return plans

    def simulate_organization(
        self, parsed_items: list[ParsedItem], organize_mode: str = "move"
    ) -> dict:
        """íŒŒì¼ ì •ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
        print("ğŸ­ íŒŒì¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")

        # ì²˜ë¦¬ ê³„íš ìƒì„±
        plans = self.create_processing_plan(parsed_items, organize_mode)

        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        simulation_results = {
            "total_files": len(plans),
            "successful": 0,
            "conflicts": 0,
            "errors": 0,
            "details": [],
        }

        for plan in plans:
            detail = {
                "source": plan.source_path,
                "target": plan.target_path,
                "action": plan.action,
                "status": "success" if not plan.conflicts else "conflict",
                "conflicts": plan.conflicts,
            }

            if plan.conflicts:
                simulation_results["conflicts"] += 1
            else:
                simulation_results["successful"] += 1

            simulation_results["details"].append(detail)

        print(
            f"âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: {simulation_results['successful']}ê°œ ì„±ê³µ, {simulation_results['conflicts']}ê°œ ì¶©ëŒ"
        )
        return simulation_results

    def _generate_target_path(self, item: ParsedItem) -> str:
        """ëŒ€ìƒ ê²½ë¡œ ìƒì„±"""
        if not self.destination_root:
            return item.sourcePath or item.path

        # íŒŒì¼ëª… ìƒì„± (ê¸°ë³¸ì ìœ¼ë¡œ ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš©)
        filename = Path(item.sourcePath or item.path).name

        # ëŒ€ìƒ ê²½ë¡œ ì¡°í•©
        return str(Path(self.destination_root) / filename)
